name: ollama-action
description: Run Ollama large language models (LLMs) with GitHub Actions
author: remarkablemark

inputs:
  model:
    description: Language model name
    required: true
  prompt:
    description: Input prompt to generate a response for
    required: true
  version:
    description: Ollama version
    required: false
  cache:
    description: Whether to cache the model
    required: false

outputs:
  response:
    description: Generated response message
    value: ${{ steps.model.outputs.response }}

runs:
  using: composite
  steps:
    - name: Setup Ollama
      uses: ai-action/setup-ollama@v1
      with:
        version: ${{ inputs.version }}

    - name: Cache model
      if: inputs.cache == 'true'
      uses: actions/cache@v4
      with:
        path: ~/.ollama
        key: ollama-action-${{ runner.os }}

    - name: Run model
      id: model
      shell: bash
      run: |
        EOF=EOF_OLLAMA_$(openssl rand -hex 12)
        {
          echo "response<<$EOF"
          ollama run $MODEL "$(printf '%q' $PROMPT)"
          echo $EOF
        } >> $GITHUB_OUTPUT
      env:
        MODEL: ${{ inputs.model }}
        PROMPT: ${{ inputs.prompt }}

branding:
  icon: terminal
  color: gray-dark
